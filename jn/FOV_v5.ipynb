{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c97d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "from pytz import timezone\n",
    "import astropy.io.fits as pf\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "from skyfield.api import load, wgs84, EarthSatellite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ca21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS NEEDED TO TRANSFORM PIXEL COORDS TO LOOK AT FOV\n",
    "\n",
    "def world2pix(lst, ra, dec, jd=None, nx=4008, ny=2672, margin=50):\n",
    "    xwcs, ywcs = world2wcs(wcspars, ra, dec, lst, jd) # Compute wcs-only pixel coordinates\n",
    "    mask = np.isfinite(xwcs) & clip_rectangle(xwcs, ywcs, nx, ny, margin) # Remove coordinates not within the margins\n",
    "    xwcs, ywcs = xwcs[mask], ywcs[mask]        \n",
    "    xpix, ypix = wcs2pix(polpars, xwcs, ywcs) # Convert to actual pixel coordinates.\n",
    "    return xpix, ypix, mask\n",
    "\n",
    "\n",
    "def clip_rectangle(x, y, nx, ny, margin):\n",
    "    maskx = (x > margin) & (x < (nx - margin))\n",
    "    masky = (y > margin) & (y < (ny - margin))\n",
    "    return maskx & masky\n",
    "\n",
    "\n",
    "def world2wcs(wcspars, ra, dec, lst=None, jd=None):\n",
    "    \"\"\" Convert world coordinates to WCS-only coordinates. \"\"\"    \n",
    "    if jd is not None:\n",
    "        ra, dec = j2000_to_equinox(ra, dec, jd)\n",
    "    w = create_wcs(wcspars, lst)\n",
    "    xwcs, ywcs = w.wcs_world2pix(ra, dec, 0)\n",
    "    return xwcs, ywcs\n",
    "\n",
    "\n",
    "def create_wcs(wcspars, lst=None):\n",
    "    \"\"\" Create and astropy WCS instance from a dictionary of parameters. \"\"\"  \n",
    "    from astropy import wcs\n",
    "    \n",
    "    if lst is not None:\n",
    "        ra0, dec0 = wcspars['crval']\n",
    "        ha0 = ra2ha(ra0, wcspars['lst'])\n",
    "        ra0 = ha2ra(ha0, lst)\n",
    "        crval = np.array([ra0, dec0])   \n",
    "    else:\n",
    "        crval = wcspars['crval']\n",
    "        \n",
    "    w = wcs.WCS(naxis=2)\n",
    "    w.wcs.crpix = wcspars['crpix']\n",
    "    w.wcs.cdelt = wcspars['cdelt']\n",
    "    w.wcs.crval = crval\n",
    "    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n",
    "    w.wcs.pc = wcspars['pc']\n",
    "    return w\n",
    "\n",
    "\n",
    "def ra2ha(ra, lst):\n",
    "    \"\"\" Convert Right Ascension to Hour Angle. \"\"\"\n",
    "    ha = np.mod(lst*15. - ra, 360.)\n",
    "    return ha\n",
    "\n",
    "def ha2ra(ha, lst):\n",
    "    \"\"\" Convert Hour Angle to Right Ascension. \"\"\"    \n",
    "    ra = np.mod(lst*15. - ha, 360.)\n",
    "    return ra\n",
    "\n",
    "\n",
    "def j2000_to_equinox(ra, dec, jd):\n",
    "    from astropy.time import Time\n",
    "    from astropy.coordinates import SkyCoord, FK5\n",
    "    t = Time(jd, scale='utc', format='jd') \n",
    "    t.format = 'jyear_str'\n",
    "    gc = SkyCoord(ra, dec, frame='fk5', unit='deg', equinox='J2000')    \n",
    "    gc = gc.transform_to(FK5(equinox=t))    \n",
    "    return gc.ra.value, gc.dec.value\n",
    "\n",
    "\n",
    "def wcs2pix(polpars, xwcs, ywcs):\n",
    "    \"\"\" Convert WCS-only coordinates to pixel coordinates. \"\"\"     \n",
    "    dx, dy = leg2d_eval(xwcs, ywcs, polpars['x_wcs2pix'], polpars['y_wcs2pix'], \n",
    "                        polpars['order'], polpars['nx'], polpars['ny'])    \n",
    "    xpix, ypix = xwcs + dx, ywcs + dy\n",
    "    return xpix, ypix\n",
    "\n",
    "\n",
    "def leg2d_eval(x, y, a, b, order=6, nx=4008., ny=2672.):\n",
    "    \"\"\" Evaluate 2-D polynomials. \"\"\"\n",
    "    mat, idx1, idx2 = leg2d_mat(x, y, order, nx, ny)\n",
    "    xres = np.dot(mat, a[idx1, idx2])\n",
    "    yres = np.dot(mat, b[idx1, idx2])\n",
    "    return xres, yres  \n",
    "\n",
    "\n",
    "def leg2d_mat(x, y, order=6, nx=4008., ny=2672.):\n",
    "    \"\"\" Create a matrix for fitting 2-D polynomials of the given order. \"\"\" \n",
    "    from numpy.polynomial import legendre\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    mat1 = legendre.legvander(2*(x/nx) - 1, order+1)\n",
    "    mat2 = legendre.legvander(2*(y/ny) - 1, order+1)\n",
    "        \n",
    "    idx1, idx2 = np.indices((order+1, order+1))\n",
    "    mask = ((idx1 + idx2) <= order)\n",
    "    idx1, idx2 = idx1[mask], idx2[mask]        \n",
    "        \n",
    "    mat = mat1[:,idx1]*mat2[:,idx2]\n",
    "    return mat, idx1, idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0b8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_tles(camid):\n",
    "\n",
    "    # Load TLEs for all passages\n",
    "    satfiles = '../test_data/3leComplete.txt'\n",
    "    with open(satfiles) as f:\n",
    "        all_tles = f.readlines()\n",
    "        f.close()   \n",
    "\n",
    "    # Split TLE list into individual lists for each TLE\n",
    "    all_tles = [i.strip() for i in all_tles]\n",
    "    tles = [all_tles[x:x+3] for x in range(0, len(all_tles), 3)]\n",
    "\n",
    "    # Reduce TLEs to Starlink only\n",
    "    starlink_tles = []\n",
    "    for tle in tles:\n",
    "        if \"STARLINK\" in tle[0]:\n",
    "            starlink_tles.append(tle)\n",
    "\n",
    "    # Obtain satellite passages\n",
    "    passed_sats = pd.read_pickle(f'../test_data/passages/passed_satellites_20221023{camid}.p')\n",
    "\n",
    "    # Find any Starlink TLEs in the passages\n",
    "    idx = []\n",
    "    flatlist = np.asarray(starlink_tles).flatten()\n",
    "    for key in passed_sats.keys():\n",
    "        line1 = passed_sats[key]['TLE line1'].strip()\n",
    "        i = np.where(flatlist == line1)[0] \n",
    "        if i.size > 0:\n",
    "            idx.append(i[0] - 1) #appending the name of the starlink sat\n",
    "\n",
    "    # Now have indices for the flattened Starlink TLE list --> divide by 3 to get indices for the original list\n",
    "    orig_idx = [int(x/3) for x in idx]\n",
    "    passed_tles = [starlink_tles[i] for i in orig_idx]\n",
    "\n",
    "    # Remove 0 labeling of first line of TLE because that's the proper format\n",
    "    for tle in passed_tles:\n",
    "        tle[0] = tle[0][2:]\n",
    "    \n",
    "    return passed_tles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ee9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starlinks = reduce_tles('LSC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44acd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_headers(camid):\n",
    "\n",
    "    images = np.sort(glob.glob(f'../test_data/diff_images/{camid}/diff_*.fits.gz'))\n",
    "    imginfo = {}\n",
    "    for img in images:\n",
    "        header = pf.getheader(img)\n",
    "        lstseq = img[-19:-11]\n",
    "        imginfo[lstseq] = {}\n",
    "        imginfo[lstseq]['JD0'] = header['JD0']\n",
    "        imginfo[lstseq]['JD1'] = header['JD1']\n",
    "        imginfo[lstseq]['midLST'] = header['MIDLST']\n",
    "        imginfo[lstseq]['midJD'] = header['MIDJD']\n",
    "        imginfo[lstseq]['nx'] = header['XSIZE']\n",
    "        imginfo[lstseq]['ny'] = header['YSIZE']\n",
    "\n",
    "    return imginfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b245377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def passage_check(midJD, tles, passages):\n",
    "        \n",
    "    idx_reduced = []\n",
    "    sats = passages[midJD].keys()\n",
    "    \n",
    "    satnums = []\n",
    "    for tle in tles:\n",
    "        satnums.append(tle[1].split()[1])\n",
    "\n",
    "    # Cross-reference\n",
    "    for i, sat in enumerate(sats):\n",
    "        if sat in satnums:\n",
    "            idx = satnums.index(sat)\n",
    "            idx_reduced.append(idx)\n",
    "  \n",
    "    return idx_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d19c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siteinfo():\n",
    "    confdir = '../fotos-python3/bringfiles/siteinfo.dat'\n",
    "    dtype = [('sitename', '|U20'), ('lat', 'float32'), ('lon', 'float32'), ('height', 'float32'), ('ID', '|U2')]\n",
    "    siteinfo = np.genfromtxt(confdir, dtype=dtype)   \n",
    "    mask = siteinfo['ID'] == 'LS'\n",
    "    siteinfo = siteinfo[mask]\n",
    "    return siteinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23bbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get timerange of all images ---- changing\n",
    "\n",
    "def image_timerange(imgdata):\n",
    "    ts = load.timescale()\n",
    "    dates = []\n",
    "    for lst in list(imgdata):\n",
    "        dates.append(imgdata[lst]['midJD'])\n",
    "\n",
    "    oldest = min(dates)\n",
    "    newest = max(dates)\n",
    "\n",
    "    t_old = Time(oldest, format='jd')\n",
    "    t_new = Time(newest, format='jd')\n",
    "\n",
    "    timerange = np.linspace(t_old, t_new, 150, endpoint=True) # every ~3mins\n",
    "\n",
    "    return ts.from_astropy(timerange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed33611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_illumination(imgdata, midJD, timerange, sat):\n",
    "\n",
    "    # Check when satellite is illuminated \n",
    "    timerange = image_timerange(imgdata)\n",
    "    sunlit = sat.at(timerange).is_sunlit(eph)\n",
    "\n",
    "    # Obtain the indices of the first and last True element for each sequence of True elements \n",
    "    sunlit_idx = []\n",
    "    start_idx = None\n",
    "    for i, elem in enumerate(sunlit):\n",
    "        if elem:\n",
    "            # Checking if the start of a sequence of True elements\n",
    "            if start_idx is None:\n",
    "                start_idx = i\n",
    "        else:\n",
    "            # Checking if a sequence is just ended\n",
    "            if start_idx is not None:\n",
    "                sunlit_idx.append((start_idx, i-1)) # -1 because we're at the first False element after True sequence\n",
    "                start_idx = None\n",
    "\n",
    "    # If the last element is True, we need to append its index as well\n",
    "    if start_idx is not None:\n",
    "        sunlit_idx.append((start_idx, len(sunlit)-1))\n",
    "    \n",
    "    # Getting the times from the indices\n",
    "    sunlit_times = []\n",
    "    for idx in sunlit_idx:\n",
    "        sunlit_times.append([timerange[idx[0]].to_astropy().value, timerange[idx[1]].to_astropy().value])\n",
    "        #sunlit_times.append([timerange.tt[idx[0]], timerange.tt[idx[1]]])\n",
    "\n",
    "    # Check if midJD is within each period and flag it if so\n",
    "    illuminated = False\n",
    "    for sunlitrng in sunlit_times:\n",
    "        if midJD >= (sunlitrng[0] - 1/86400) and midJD <= (sunlitrng[1] + 1/86400): #adding a bumper of one second\n",
    "            illuminated = True\n",
    "            if illuminated:\n",
    "                break\n",
    "\n",
    "    return illuminated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b279b",
   "metadata": {},
   "source": [
    "## Need to keep the JD0 and JD1 for each image!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b183211",
   "metadata": {},
   "source": [
    "### I think we should re-write ProduceSkyPositions such that it:\n",
    "\n",
    "- begins with an image\n",
    "- extracts JD0, JD1, midJD\n",
    "- reduces passages to those dates\n",
    "- reduces the reduced passages to determined starlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd82e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2459876.52443372: {'JD0': {2459876.524655353: ['48366U', '51788U']}, 'JD1': {2459876.524729224: ['48366U', '51788U']}}}\n",
      "{'JD0': {2459876.524655353: ['48366U', '51788U']}, 'JD1': {2459876.524729224: ['48366U', '51788U']}}\n"
     ]
    }
   ],
   "source": [
    "#### NOTE\n",
    "\n",
    "header = pf.getheader('../test_data/diff_images/LSC/diff_48506377LSC.fits.gz')\n",
    "jd0 = header['JD0']\n",
    "jd1 = header['JD1']\n",
    "midJD = header[12]\n",
    "\n",
    "# If we want all info such that: \n",
    "# Keys = midJDs: midJD --> [ [ jd0 -> [sats] ] , [ jd1 -> [sats] ] ] ... next midJD (each midJD is a spearate key)\n",
    "\n",
    "sat1 = '48366U'\n",
    "sat2 = '51788U'\n",
    "v1 = {}\n",
    "v1 = {midJD: {'JD0': {jd0: [sat1, sat2]}, 'JD1': {jd1: [sat1, sat2]}}}\n",
    "print(v1)\n",
    "\n",
    "# However, for reducing the passages in ProduceSkyPositions, it will be easier to just have:\n",
    "# Keys = JD0s and JD1s: jd0 --> [sats] , jd1 --> [sats] , ... next JD0 and JD1 (each JD is a separate key)\n",
    "\n",
    "v2 = {}\n",
    "v2 = {'JD0': {jd0: [sat1, sat2]}, 'JD1': {jd1: [sat1, sat2]}}\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa3807",
   "metadata": {},
   "source": [
    "## Should have LSTSEQ ????\n",
    "\n",
    "Keys: LSTSEQs\n",
    "\n",
    "Subkeys: JD0 and JD1 for that LSTSEQ (since corresponds to a single image)\n",
    "\n",
    "- JD0 $\\rightarrow$ [sat1, sat2, sat3, ...]\n",
    "- JD1 $\\rightarrow$ [sat1, sat2, sat3, ...]\n",
    "\n",
    "... next LSTSEQ \n",
    "\n",
    "\n",
    "#### NOTE: I think I should also include midJD\n",
    "\n",
    "Keys: LSTSEQs\n",
    "\n",
    "Subkeys: JD0, JD1, midJD for that LSTSEQ (since corresponds to a single image)\n",
    "\n",
    "- JD0 $\\rightarrow$ [sat1, sat2, sat3, ...]\n",
    "- JD1 $\\rightarrow$ [sat1, sat2, sat3, ...]\n",
    "- midJD $\\rightarrow$ [sat1, sat2, sat3, ...]\n",
    "\n",
    "... next LSTSEQ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9986fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing main function such that JD0s and JD1s are recorded WITH LSTSEQ\n",
    "\n",
    "eph = load('de421.bsp')\n",
    "\n",
    "def check_each_camid():\n",
    "    imgdata = []\n",
    "    times = []\n",
    "    fasts = []\n",
    "    psgs = []\n",
    "    tles = []\n",
    "    camids = ['LSC','LSE']\n",
    "    pooldicts = [{}] * len(camids)\n",
    "    \n",
    "    print('Collecting image information\\n')\n",
    "    for camid in camids:\n",
    "        d = image_headers(camid)\n",
    "        imgdata.append(d)\n",
    "        times.append(image_timerange(d))\n",
    "        fasts.append(h5py.File(f\"../fast_20221023{camid}.hdf5\", \"r\"))\n",
    "        psgs.append(pd.read_pickle(f\"../test_data/passages/passages_20221023{camid}.p\"))\n",
    "        tles.append(reduce_tles(camid))\n",
    "    \n",
    "    # Define observer\n",
    "    site = get_siteinfo()\n",
    "    mascara = wgs84.latlon(latitude_degrees=site[0][1], longitude_degrees=site[0][2], elevation_m=site[0][3])\n",
    "    \n",
    "    print('Beginning Loop\\n')\n",
    "    for seq in fasts[0]['station']['lstseq'][:]: \n",
    "        lstseq = str(seq)\n",
    "\n",
    "        for data, timerange, camid, fast, starlinks, passages, pool, in zip(\n",
    "            imgdata, times, camids, fasts, tles, psgs, pooldicts):\n",
    "\n",
    "            if lstseq not in data.keys():\n",
    "                #print(f'{lstseq} not in directory')\n",
    "                continue #this is only needed if not going through ALL images!\n",
    "\n",
    "            # Set time of image\n",
    "            midJD = data[lstseq]['midJD']\n",
    "            ts = load.timescale()\n",
    "            t = Time(midJD, format='jd')\n",
    "\n",
    "            # Obtain passages\n",
    "            idx_reduced = passage_check(midJD, starlinks, passages)\n",
    "\n",
    "            #if idx_reduced is None: ## THIS IS WRONG!!!!!!\n",
    "            if len(idx_reduced) == 0:\n",
    "                print(f'{lstseq}: No starlinks passing MASCARA')\n",
    "                continue\n",
    "\n",
    "            # print(f'There are {len(idx_reduced)} Starlinks passing overhead {camid} for LSTSEQ={lstseq}')\n",
    "            # Sun must be low enough below the horizon, otherwise data is not good enough\n",
    "            observer = mascara + eph['earth']\n",
    "            sun_pos = observer.at(ts.from_astropy(t)).observe(eph['sun'])\n",
    "            sun_alt, sun_az, sun_dist = sun_pos.apparent().altaz()\n",
    "\n",
    "            if sun_alt.degrees <= -18.:\n",
    "                # Attaining the astrometric solution (depends on FAST file and LSTseq)\n",
    "                astro = np.where((fast['astrometry/lstseq'][:] // 50) == (int(lstseq) // 50))[0][0]\n",
    "                order = fast['astrometry/x_wcs2pix'][astro].shape[0]-1\n",
    "                lst=fast['station/lst'][np.where(fast['station/lstseq'][:]==(fast['astrometry/lstseq'][astro]))[0][0]]\n",
    "                nx = data[lstseq]['nx']\n",
    "                ny = data[lstseq]['ny']\n",
    "\n",
    "                wcspars = { 'crval' : fast['astrometry/crval'][astro].copy(),\n",
    "                            'crpix' : fast['astrometry/crpix'][astro].copy(),\n",
    "                            'cdelt' : [0.02148591731740587,0.02148591731740587],\n",
    "                            'pc'    : fast['astrometry/pc'][astro].copy(),\n",
    "                            'lst'   : lst }\n",
    "\n",
    "                polpars = { 'x_wcs2pix' : fast['astrometry/x_wcs2pix'][astro].copy(),\n",
    "                            'y_wcs2pix' : fast['astrometry/y_wcs2pix'][astro].copy(),\n",
    "                            'x_pix2wcs' : fast['astrometry/x_pix2wcs'][astro].copy(),\n",
    "                            'y_pix2wcs' : fast['astrometry/y_pix2wcs'][astro].copy(),\n",
    "                            'nx'    : nx,\n",
    "                            'ny'    : ny,\n",
    "                            'order' : order }\n",
    "\n",
    "                jd0 = data[lstseq]['JD0']\n",
    "                jd1 = data[lstseq]['JD1']\n",
    "                midLST = data[lstseq]['midLST']\n",
    "\n",
    "                for idx in idx_reduced:\n",
    "                    line1 = starlinks[idx][0]\n",
    "                    line2 = starlinks[idx][1]\n",
    "                    line3 = starlinks[idx][2] \n",
    "                    sat = EarthSatellite(line2, line3, line1, ts)\n",
    "\n",
    "                    diff = sat - mascara\n",
    "                    topocentric = diff.at(ts.from_astropy(t))\n",
    "                    alt, az, dist = topocentric.altaz()\n",
    "\n",
    "                    # Criteria check: if satellite is >20 degrees above the horizon\n",
    "                    if alt.degrees >= 20:\n",
    "\n",
    "                        # Criteria check: if satellite is illuminated\n",
    "                        illuminated = check_illumination(data, midJD, timerange, sat)\n",
    "\n",
    "                        if illuminated:\n",
    "                            ra, dec, radec_dist = topocentric.radec() \n",
    "                            radeg = ra._degrees\n",
    "                            dedeg = dec._degrees\n",
    "                            ra, dec = j2000_to_equinox(radeg, dedeg, midJD)\n",
    "                            w = create_wcs(wcspars, midLST)\n",
    "                            xwcs, ywcs = w.wcs_world2pix(ra, dec, 0)\n",
    "                            mask = np.isfinite(xwcs) & clip_rectangle(xwcs, ywcs, nx, ny, margin=50)\n",
    "\n",
    "                            if mask:\n",
    "\n",
    "                                if lstseq not in pool:\n",
    "                                    pool[lstseq] = {}\n",
    "\n",
    "                                if jd0 not in pool[lstseq]:\n",
    "                                    pool[lstseq][jd0] = {}\n",
    "                                    pool[lstseq][jd0] = [line2[2:8]]\n",
    "                                else:\n",
    "                                    if line2[2:8] not in pool[lstseq][jd0]:\n",
    "                                        pool[lstseq][jd0].append(line2[2:8])\n",
    "\n",
    "                                if jd1 not in pool[lstseq]:\n",
    "                                    pool[lstseq][jd1] = {}\n",
    "                                    pool[lstseq][jd1] = [line2[2:8]]\n",
    "                                else:    \n",
    "                                    if line2[2:8] not in pool[lstseq][jd1]:\n",
    "                                        pool[lstseq][jd1].append(line2[2:8])\n",
    "\n",
    "                                if midJD not in pool[lstseq]:\n",
    "                                    pool[lstseq][midJD] = {}\n",
    "                                    pool[lstseq][midJD] = [line2[2:8]]\n",
    "                                else:    \n",
    "                                    if line2[2:8] not in pool[lstseq][midJD]:\n",
    "                                        pool[lstseq][midJD].append(line2[2:8])\n",
    "                                            \n",
    "                                \n",
    "\n",
    "\n",
    "    for fast in fasts:\n",
    "        fast.close()\n",
    "        \n",
    "    for (pool, camid) in zip(pooldicts, camids):\n",
    "    \n",
    "        if len(pool) > 0:\n",
    "            pickle.dump(pool, open(f'../jd_test/pool_{camid}.p', 'wb'))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe90b9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image information\n",
      "\n",
      "Beginning Loop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_each_camid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "47dd055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = pd.read_pickle(\"../test_data/passages/passages_20221023LSC.p\")\n",
    "pool = pd.read_pickle('../jd_test/pool_LSC.p') # these are populated with JD0s, JD1s, and midJDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6975e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce JDs in passages to just (jd0, jd1, midJD)\n",
    "Y = {}\n",
    "for JD, data in passages.items():\n",
    "    if JD in [JD0, JD1, midJD]:\n",
    "        Y[JD] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d0d01eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2459876.520887864, 2459876.520961742, 2459876.520740109]\n",
      "[2459876.520740109, 2459876.520887864, 2459876.520961742]\n"
     ]
    }
   ],
   "source": [
    "print([JD0, JD1, midJD])\n",
    "print(list(pool['48506377']))\n",
    "print(list(Y))\n",
    "\n",
    "# Why Y begin wih midJD? Does it matter? (don't think so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea90a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reduce satnums in each JD of Y\n",
    "\n",
    "Z = {}\n",
    "for JD in Y:\n",
    "    Z[JD] = {}\n",
    "    for satnum in pool[lstseq][JD]:\n",
    "        if satnum in Y[JD]:\n",
    "            Z[JD][satnum] = Y[JD][satnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3010674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459876.52443372 ['48366U', '51788U']\n",
      "2459876.524655353 ['48366U', '51788U']\n",
      "2459876.524729224 ['48366U', '51788U']\n"
     ]
    }
   ],
   "source": [
    "for jd in Z.keys():\n",
    "    print(jd, list(Z[jd]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59db10",
   "metadata": {},
   "source": [
    "### OKAY: \n",
    "\n",
    "We now have a working code that reduces the passages to JD0, JD1, midJD - and for only the satellites determined for each of these JDs.\n",
    "\n",
    "So, we do this all iteratively for each LSTSEQ, i.e. for each image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64b168a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = pd.read_pickle('../selection_pool/pool_LSC.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73296743",
   "metadata": {},
   "source": [
    "### There should be 3 entries for each LSTSEQ.. (i.e. JD0, JD1, and midJD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a1df96ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 48506624\n",
      "[2459876.542901684, 2459876.542975561]\n",
      "['53603U', '47795U', '45733U']\n",
      "['53603U', '47795U', '45733U']\n"
     ]
    }
   ],
   "source": [
    "for i, lstseq in enumerate(pool.keys()):\n",
    "    if len(pool[lstseq]) != 3:\n",
    "        print(i, lstseq)\n",
    "        print(list(pool[lstseq]))\n",
    "        for jd in pool[lstseq]:\n",
    "            print(list(pool[lstseq][jd]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a51e847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2459876.542901684: ['53603U', '47795U', '45733U'],\n",
       " 2459876.542975561: ['53603U', '47795U', '45733U']}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool['48506624']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cc9520f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-24 01:01:46.706\n",
      "2022-10-24 01:01:53.088\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lstseq in pool.keys():\n",
    "    if len(pool[lstseq]) != 3:\n",
    "        for jd in pool[lstseq]:\n",
    "            t = Time(jd, format='jd')\n",
    "            print(t.iso) \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198852d2",
   "metadata": {},
   "source": [
    "### REASON FOUND! midJD = JD0. So, we will have to label the dictionary differently..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "de1e5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "tles = reduce_tles('LSC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "103486de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2459876.520887876: ['49424U', '47800U'],\n",
       " 2459876.520961753: ['49424U', '47800U'],\n",
       " 2459876.520740121: ['49424U', '47800U']}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool['48506326']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "79da6cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD0 2022-10-24 00:30:04.711\n",
      "JD1 2022-10-24 00:30:11.095\n",
      "mJD 2022-10-24 00:29:51.945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = pf.getheader(f'../selection_pool/diff_48506326LSC.fits.gz')\n",
    "lstseq = '48506326'\n",
    "midJD = header['midJD']\n",
    "jd0 = header['JD0']\n",
    "jd1 = header['JD1']\n",
    "\n",
    "labs = ['JD0', 'JD1', 'mJD']\n",
    "\n",
    "for i, jd in enumerate([jd0, jd1, midJD]):\n",
    "    t = Time(jd, format='jd')\n",
    "    print(labs[i], t.iso) \n",
    "    \n",
    "len(tles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "198a7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW check passages code\n",
    "\n",
    "# idx_reduced = []\n",
    "# sats_mid = passages[midJD].keys()\n",
    "# sats_jd0 = passages[jd0].keys()\n",
    "# sats_jd1 = passages[jd1].keys()\n",
    "\n",
    "# satnums = []\n",
    "# for tle in tles:\n",
    "#     satnums.append(tle[1].split()[1])\n",
    "    \n",
    "# common_sats = set(sats_mid).intersection(sats_jd0, sats_jd1)\n",
    "\n",
    "# # Cross-reference\n",
    "# for sat in common_sats:\n",
    "#     if sat in satnums:\n",
    "#         idx = satnums.index(sat)\n",
    "#         idx_reduced.append(idx)\n",
    "        \n",
    "# ## TEST\n",
    "\n",
    "# test_mid = ['49447U', '44928U', '02481U', '02766U', '02971U']\n",
    "# test_jd0 = ['02971U', '48264U', '40204U', '49447U', '44928U']\n",
    "# test_jd1 = ['44928U', '40204U', '49447U', '40485U', '48264U']\n",
    "\n",
    "# common_sats = set(test_mid).intersection(test_jd0, test_jd1)\n",
    "\n",
    "# idx_reduced = []\n",
    "# for sat in common_sats:\n",
    "#     print(sat)\n",
    "#     if sat in satnums:\n",
    "#         idx = satnums.index(sat)\n",
    "#         idx_reduced.append(idx)\n",
    "        \n",
    "# for idx in idx_reduced:\n",
    "#     print(tles[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ceea6f",
   "metadata": {},
   "source": [
    "Why is is that pool[lstseq] JDs don't match that of the image header info? Should be the same!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d8223068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-24 00:29:51.945\n",
      "2022-10-24 00:30:04.711\n",
      "2022-10-24 00:30:11.095\n",
      "\n",
      "\n",
      "2022-10-24 00:30:04.712\n",
      "2022-10-24 00:30:11.095\n",
      "2022-10-24 00:29:51.946\n"
     ]
    }
   ],
   "source": [
    "from astropy.time import Time\n",
    "\n",
    "for jd in Y:\n",
    "    t = Time(jd, format='jd')\n",
    "    print(t.iso)\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "for jd in pool[lstseq]:\n",
    "    t = Time(jd, format='jd')\n",
    "    print(t.iso)\n",
    "    \n",
    "# NOTE: ordering is 'wrong'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b44393",
   "metadata": {},
   "source": [
    "#### OKAY SO THE DIFFERENCE IS TEENY TINY.... numerical error? how to account for this???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cadca2",
   "metadata": {},
   "source": [
    "It is possible that the slight difference is due to floating-point round-off errors, which is common in many programming languages including Python. One approach to handle this is to use a tolerance level when comparing the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "27a713b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48506326\n",
      "2459876.520887864 2459876.520961742 2459876.520740109\n"
     ]
    }
   ],
   "source": [
    "for lstseq in pool.keys():\n",
    "    \n",
    "    # For now, just selecting LSTSEQ we have\n",
    "    header = pf.getheader(f'../selection_pool/diff_{lstseq}LSC.fits.gz')\n",
    "    JD0 = header['JD0']\n",
    "    JD1 = header['JD1']\n",
    "    midJD = header['midJD']\n",
    "    \n",
    "    print(lstseq)\n",
    "    print(JD0, JD1, midJD)\n",
    "    \n",
    "    Y = {}\n",
    "    for date in [JD0, JD1, midJD]:\n",
    "        for JD, data in passages.items():\n",
    "            if date == JD:\n",
    "                Y[JD] = data\n",
    "                \n",
    "    # nested for loop so as to make sure the 'correct' order is given\n",
    "            \n",
    "            \n",
    "    # Now reduce satnums in each JD of Y\n",
    "#     Z = {}\n",
    "#     for JD in Y:\n",
    "#         Z[JD] = {}\n",
    "#         for satnum in pool[lstseq][JD]:\n",
    "#             if satnum in Y[JD]:\n",
    "#                 Z[JD][satnum] = Y[JD][satnum]\n",
    "                \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b3c5b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459876.520887864 00:30:04.711\n",
      "2459876.520961742 00:30:11.095\n",
      "2459876.520740109 00:29:51.945\n",
      "\n",
      "\n",
      "2459876.520887876 00:30:04.712\n",
      "2459876.520961753 00:30:11.095\n",
      "2459876.520740121 00:29:51.946\n"
     ]
    }
   ],
   "source": [
    "for jd in Y:\n",
    "    t = Time(jd, format='jd')\n",
    "    print(jd, t.iso[11:])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "for jd in pool[lstseq]:\n",
    "    t = Time(jd, format='jd')\n",
    "    print(jd, t.iso[11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d76340a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new dictionary with keys corrected for floating-point round-off errors\n",
    "\n",
    "# import math\n",
    "# T = 0.0000001\n",
    "\n",
    "# Z = {}\n",
    "# for yjd in Y:\n",
    "    \n",
    "#     Z[yjd] = {}\n",
    "    \n",
    "#     for pjd in pool[lstseq][yjd]:\n",
    "        \n",
    "#         if math.isclose(yjd, pjd, rel_tol=T):\n",
    "#             print(pool[pjd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "135321ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2459876.520887876: ['49424U', '47800U'],\n",
       " 2459876.520961753: ['49424U', '47800U'],\n",
       " 2459876.520740121: ['49424U', '47800U']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool[lstseq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df843c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2459876.520887864, 2459876.520961742, 2459876.520740109]\n",
      "[2459876.520887876, 2459876.520961753, 2459876.520740121]\n"
     ]
    }
   ],
   "source": [
    "print(list(Y))\n",
    "print(list(pool[lstseq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f51f697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary with keys corrected for floating-point round-off errors\n",
    "\n",
    "tolerance = 1e-6\n",
    "Z = {}\n",
    "\n",
    "for yJD in Y:\n",
    "    for pJD in pool[lstseq]:\n",
    "        \n",
    "        if abs(yJD - pJD) <= tolerance:\n",
    "            Z[pJD] = {}\n",
    "            \n",
    "            for sat in pool[lstseq][pJD]:\n",
    "                \n",
    "                Z[pJD][sat] = {}\n",
    "                \n",
    "                for k, v in Y[yJD].items():\n",
    "                    if k == sat:\n",
    "                        Z[pJD][sat][k] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a19cc7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2459876.520887876: {'49424U': {}, '47800U': {}},\n",
       " 2459876.520961753: {'49424U': {}, '47800U': {}},\n",
       " 2459876.520740121: {'49424U': {}, '47800U': {}}}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cd31a",
   "metadata": {},
   "source": [
    "### Description of problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ae02b",
   "metadata": {},
   "source": [
    "#### First issue: midJD < JD0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7fa6bc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD0 2022-10-24 00:30:04.711\n",
      "JD1 2022-10-24 00:30:11.095\n",
      "mJD 2022-10-24 00:29:51.945\n"
     ]
    }
   ],
   "source": [
    "lstseq = '48506326'\n",
    "\n",
    "header = pf.getheader(f'../selection_pool/diff_{lstseq}LSC.fits.gz')\n",
    "midJD = header['midJD']\n",
    "jd0 = header['JD0']\n",
    "jd1 = header['JD1']\n",
    "\n",
    "labs = ['JD0', 'JD1', 'mJD']\n",
    "for i, jd in enumerate([jd0, jd1, midJD]):\n",
    "    t = Time(jd, format='jd')\n",
    "    print(labs[i], t.iso) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bc0f7911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passages reduced from 4492 to 3\n"
     ]
    }
   ],
   "source": [
    "# Reduce Passages file (keys = JDs) to the given JDs\n",
    "\n",
    "Y = {}\n",
    "for date in [JD0, JD1, midJD]:\n",
    "    for JD, data in passages.items():\n",
    "        if date == JD:\n",
    "            Y[JD] = data\n",
    "            \n",
    "print(f'Passages reduced from {len(passages)} to {len(Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fc10e7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2459876.520887876: ['49424U', '47800U'],\n",
       " 2459876.520961753: ['49424U', '47800U'],\n",
       " 2459876.520740121: ['49424U', '47800U']}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the selection pool for the LSTSEQ we're testing:\n",
    "pool[lstseq]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c73860",
   "metadata": {},
   "source": [
    "We now want to reduce the satellites in Y to those in our selection pool (while keeping all the relevant info from Y such as positions etc). We do this by matching the JDs in both dictionaries - second issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a20a2",
   "metadata": {},
   "source": [
    "#### Second issue: floating-point round-off errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "029977a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459876.520887864 00:30:04.711\n",
      "2459876.520961742 00:30:11.095\n",
      "2459876.520740109 00:29:51.945\n",
      "\n",
      "\n",
      "2459876.520887876 00:30:04.712\n",
      "2459876.520961753 00:30:11.095\n",
      "2459876.520740121 00:29:51.946\n"
     ]
    }
   ],
   "source": [
    "for jd in Y:\n",
    "    t = Time(jd, format='jd')\n",
    "    print(jd, t.iso[11:])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "for jd in pool[lstseq]:\n",
    "    t = Time(jd, format='jd')\n",
    "    print(jd, t.iso[11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fe6a7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We account for this by adding a tolerance:\n",
    "\n",
    "tolerance = 1e-6\n",
    "Z = {}\n",
    "\n",
    "for yJD in Y:\n",
    "    for pJD in pool[lstseq]:\n",
    "        \n",
    "        if abs(yJD - pJD) <= tolerance:\n",
    "            Z[pJD] = {}\n",
    "            \n",
    "            for sat in pool[lstseq][pJD]:\n",
    "                \n",
    "                Z[pJD][sat] = {}\n",
    "                \n",
    "                for k, v in Y[yJD].items():\n",
    "                    if k == sat:\n",
    "                        Z[pJD][sat][k] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4cc70727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2459876.520887876: {'49424U': {}, '47800U': {}},\n",
       " 2459876.520961753: {'49424U': {}, '47800U': {}},\n",
       " 2459876.520740121: {'49424U': {}, '47800U': {}}}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f9eb9d",
   "metadata": {},
   "source": [
    "#### Z is empty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bcf6154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satellite not found\n",
      "Satellite not found\n",
      "Satellite not found\n",
      "Satellite not found\n",
      "Satellite not found\n",
      "Satellite not found\n"
     ]
    }
   ],
   "source": [
    "sats = ['49424U', '47800U']\n",
    "\n",
    "for sat in sats:\n",
    "    if sat not in Y[jd0]:\n",
    "        print('Satellite not found')\n",
    "        \n",
    "for sat in sats:\n",
    "    if sat not in Y[jd1]:\n",
    "        print('Satellite not found')\n",
    "        \n",
    "for sat in sats:\n",
    "    if sat not in Y[midJD]:\n",
    "        print('Satellite not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee798f",
   "metadata": {},
   "source": [
    "#### Third issue: the satellites in our selection pool are not found in the passage file for their respective JD. ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3ee34d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "passed = pd.read_pickle(\"../test_data/passages/passed_satellites_20221023LSC.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f08e949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nope!\n",
      "Nope!\n"
     ]
    }
   ],
   "source": [
    "for sat in sats:\n",
    "    if sat not in passages.keys():\n",
    "        print('Nope!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5f32c",
   "metadata": {},
   "source": [
    "Interesting, the satellites in the selection pool are not in the passed satellites files either.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "68659753",
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_sats = passed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bad3659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []\n",
    "\n",
    "for tle in tles:\n",
    "    if tle[1][2:8] in passed_sats:\n",
    "        match.append(tle[1][2:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b64210b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931\n",
      "931\n"
     ]
    }
   ],
   "source": [
    "print(len(tles))\n",
    "print(len(match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "50bd60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sat in sats:\n",
    "    if sat in match:\n",
    "        print('Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753ab61",
   "metadata": {},
   "source": [
    "#### STRANGE: the satellites in the selection pool are not within the Starlink TLEs! This is a BIG error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "45fd9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdata = []\n",
    "times = []\n",
    "psgs = []\n",
    "starlinks = []\n",
    "camids = ['LSC','LSE']\n",
    "\n",
    "for camid in camids:\n",
    "    d = image_headers(camid)\n",
    "    imgdata.append(d)\n",
    "    times.append(image_timerange(d))\n",
    "    psgs.append(pd.read_pickle(f\"../test_data/passages/passages_20221023{camid}.p\"))\n",
    "    starlinks.append(reduce_tles(camid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8a859539",
   "metadata": {},
   "outputs": [],
   "source": [
    "satfiles = '../test_data/3leComplete.txt'\n",
    "with open(satfiles) as f:\n",
    "    all_tles = f.readlines()\n",
    "    f.close()   \n",
    "\n",
    "# Split TLE list into individual lists for each TLE\n",
    "all_tles = [i.strip() for i in all_tles]\n",
    "alltles = [all_tles[x:x+3] for x in range(0, len(all_tles), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8c67d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "satnums = []\n",
    "for tle in alltles:\n",
    "    satnums.append(tle[1][2:8])\n",
    "    \n",
    "for sat in sats:\n",
    "    if sat in satnums:\n",
    "        print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5b6df6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3179"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce TLEs to Starlink only\n",
    "starlink_tles = []\n",
    "for tle in alltles:\n",
    "    if \"STARLINK\" in tle[0]:\n",
    "        starlink_tles.append(tle)\n",
    "        \n",
    "len(starlink_tles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "68d6188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "satnums = []\n",
    "for tle in starlink_tles:\n",
    "    satnums.append(tle[1][2:8])\n",
    "\n",
    "test = []\n",
    "for i, satnum in enumerate(satnums):\n",
    "    if satnum in list(passed):\n",
    "        test.append(i-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8af8d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 ms ± 1.46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "idx = []\n",
    "flatlist = np.asarray(starlink_tles).flatten()\n",
    "line1_list = [passed[key]['TLE line1'].strip() for key in passed.keys()]\n",
    "idx = [np.where(flatlist == line)[0][0] - 1 for line in line1_list if np.where(flatlist == line)[0].size > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "81ff0e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260 ms ± 1.32 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "idx = []\n",
    "flatlist = np.asarray(starlink_tles).flatten()\n",
    "for key in passed.keys():\n",
    "    line1 = passed[key]['TLE line1'].strip()\n",
    "    i = np.where(flatlist == line1)[0] \n",
    "    if i.size > 0:\n",
    "        idx.append(i[0] - 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a5120156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if test == idx:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "02e092f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now have indices for the flattened Starlink TLE list --> divide by 3 to get indices for the original list\n",
    "orig_idx = [int(x/3) for x in idx]\n",
    "passed_tles = [starlink_tles[i] for i in orig_idx]\n",
    "\n",
    "# Remove 0 labeling of first line of TLE because that's the proper format\n",
    "for tle in passed_tles:\n",
    "    tle[0] = tle[0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e7f16d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47800U 19292\n",
      "49424U 20699\n"
     ]
    }
   ],
   "source": [
    "for i, tle in enumerate(alltles):\n",
    "    if sats[0] == tle[1][2:8]:\n",
    "        print(sats[0], i)\n",
    "    if sats[1] == tle[1][2:8]:\n",
    "        print(sats[1], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "00a39cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47800U 1019\n",
      "49424U 1587\n"
     ]
    }
   ],
   "source": [
    "for i, tle in enumerate(starlink_tles):\n",
    "    if sats[0] == tle[1][2:8]:\n",
    "        print(sats[0], i)\n",
    "    if sats[1] == tle[1][2:8]:\n",
    "        print(sats[1], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "4fac19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sat in enumerate(list(passed)):\n",
    "    if sats[0] == sat:\n",
    "        print(sats[0], i)\n",
    "    if sats[1] == sat:\n",
    "        print(sats[1], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3ed38af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48367U\n",
      "51790U\n"
     ]
    }
   ],
   "source": [
    "satnums = []\n",
    "for tle in tles:\n",
    "    satnums.append(tle[1].split()[1])\n",
    "\n",
    "idx_reduced = []\n",
    "for i, sat in enumerate(passages[midJD].keys()):\n",
    "    if sat in satnums:\n",
    "        print(sat)\n",
    "        idx = satnums.index(sat)\n",
    "        idx_reduced.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "47ba5ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48367U\n",
      "51790U\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10, 12]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_reduced = []\n",
    "sats_mid = passages[midJD].keys()\n",
    "sats_jd0 = passages[jd0].keys()\n",
    "sats_jd1 = passages[jd1].keys()\n",
    "\n",
    "satnums = []\n",
    "for tle in tles:\n",
    "    satnums.append(tle[1].split()[1])\n",
    "\n",
    "common_sats = set(sats_mid).intersection(sats_jd0, sats_jd1)\n",
    "\n",
    "# Cross-reference\n",
    "for sat in common_sats:\n",
    "    if sat in satnums:\n",
    "        print(sat)\n",
    "        idx = satnums.index(sat)\n",
    "        idx_reduced.append(idx)\n",
    "        \n",
    "idx_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "f3a5a7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STARLINK-2643',\n",
       " '1 48367U 21038Q   22294.99038760 -.00000807  00000-0 -35314-4 0  9990',\n",
       " '2 48367  53.0539 134.4060 0001353 125.3004 234.8111 15.06396799 81060']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tles[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0c5c1868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2459876.520887876: ['49424U', '47800U'],\n",
       " 2459876.520961753: ['49424U', '47800U'],\n",
       " 2459876.520740121: ['49424U', '47800U']}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool[lstseq]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
