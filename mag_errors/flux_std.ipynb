{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "894e14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.io.fits as pf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rootdir = '/Users/peter/Projects/master-thesis/mag_errors/'\n",
    "starlink_data = '/Users/peter/Projects/starlink_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2a9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flux files\n",
    "ff = np.sort(glob.glob(f'{rootdir}satflux/*.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4582375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/Users/peter/Projects/master-thesis/mag_errors/satflux/satflux_LSC.p',\n",
       "       '/Users/peter/Projects/master-thesis/mag_errors/satflux/satflux_LSE.p',\n",
       "       '/Users/peter/Projects/master-thesis/mag_errors/satflux/satflux_LSN.p',\n",
       "       '/Users/peter/Projects/master-thesis/mag_errors/satflux/satflux_LSS.p',\n",
       "       '/Users/peter/Projects/master-thesis/mag_errors/satflux/satflux_LSW.p'],\n",
       "      dtype='<U68')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df122d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "168\n",
      "291\n",
      "437\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "for i in ff:\n",
    "    x = pd.read_pickle(i)\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf2727e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = []\n",
    "popts = []\n",
    "pcovs = []\n",
    "perrs = []\n",
    "for i in ff[1:]:\n",
    "    x = pd.read_pickle(i)\n",
    "    lstseqs = x.keys()\n",
    "    for lstseq in lstseqs:\n",
    "        satnums = list(x[lstseq])[2:]\n",
    "        for satnum in satnums:\n",
    "            fluxes.append(x[lstseq][satnum]['satflux'])\n",
    "            popts.append(x[lstseq][satnum]['popt'])\n",
    "            pcovs.append(x[lstseq][satnum]['pcov'])\n",
    "            perrs.append(x[lstseq][satnum]['perr'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e09d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.copy(fluxes)\n",
    "for i, x in enumerate(test):\n",
    "    test[i] = 10**x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15acee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32922015919226466\n",
      "63198.495750210684\n"
     ]
    }
   ],
   "source": [
    "print(np.std(fluxes))\n",
    "print(np.std(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8dea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prop(logFlux, sigma_B):\n",
    "    \"\"\"\n",
    "    m = -2.5log10(F) + B\n",
    "    \n",
    "    sigma_m = sqrt([(dm/dF)*sigma_F]**2 + [(dm/dB)*sigma_B]**2)\n",
    "    \n",
    "        => dm/dF = -2.5 * d/dF[log10(F)] = -2.5/F*ln(10)\n",
    "        => dm/dB = 1\n",
    "    \n",
    "    sigma_m = sqrt([(-2.5/F*ln(10)) * sigma_F]**2 + [sigma_B]**2)\n",
    "    \n",
    "    sigma_F = uncertainty due to photon noise = np.std(fluxes)\n",
    "    sigma_B = uncertainty due to background noise = pcov\n",
    "    \n",
    "    \"\"\"\n",
    "    sigma_F = 63198.495750210684\n",
    "    F = 10**logFlux\n",
    "    return np.sqrt(((-2.5/(F*np.log(10))) * sigma_F)**2 + (sigma_B)**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef187ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6297948157081845\n"
     ]
    }
   ],
   "source": [
    "sigma_m = error_prop(fluxes[0], pcovs[0])\n",
    "print(sigma_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5e3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prop_logged(F, sigma_B):\n",
    "    \"\"\"\n",
    "    m = -2.5*F + B\n",
    "    \n",
    "    sigma_m = sqrt([(dm/dF)*sigma_F]**2 + [(dm/dB)*sigma_B]**2)\n",
    "    \n",
    "        => dm/dF = -2.5 \n",
    "        => dm/dB = 1\n",
    "    \n",
    "    sigma_m = sqrt([(-2.5) * sigma_F]**2 + [sigma_B]**2)\n",
    "    \n",
    "    sigma_F = uncertainty due to photon noise = np.std(fluxes)\n",
    "    sigma_B = uncertainty due to background noise = pcov\n",
    "    \n",
    "    \"\"\"\n",
    "    sigma_F = 0.32922015919226466\n",
    "    sigma_m = np.sqrt(((-2.5) * sigma_F)**2 + (sigma_B)**2)\n",
    "    print(sigma_m)\n",
    "\n",
    "# Unfortunately, this isn't the correct way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7901191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823051784963984\n"
     ]
    }
   ],
   "source": [
    "error_prop_logged(fluxes[0], pcovs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8822d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.630257604377099\n"
     ]
    }
   ],
   "source": [
    "def error_prop_correct(logFlux, sigma_B):\n",
    "    \"\"\"\n",
    "    m = -2.5*log10(F) + B\n",
    "    \n",
    "    sigma_m = sqrt([(dm/dF)*sigma_F]**2 + [(dm/dB)*sigma_B]**2)\n",
    "    \n",
    "        => dm/dF = -2.5/F*ln(10)\n",
    "        => dm/dB = 1\n",
    "        => sigma_F = 63198.495750210684\n",
    "        => sigma_B = np.sqrt(pcov) = perr   \n",
    "\n",
    "    sigma_m = sqrt([(-2.5/F*ln(10)) * sigma_F]**2 + [sigma_B]**2)\n",
    "    sigma_F = uncertainty from flux => std of flux distribution provides an estimate\n",
    "    sigma_B = uncertainty from background => std of the fit parameter B = perr \n",
    "    \n",
    "    \"\"\"\n",
    "    sigma_F = 63198.495750210684\n",
    "    F = 10**logFlux\n",
    "    sigma_m = np.sqrt(((-2.5/(F*np.log(10))) * sigma_F)**2 + (sigma_B)**2)\n",
    "    print(sigma_m)\n",
    "\n",
    "# x = np.sqrt(pcovs[0])\n",
    "error_prop_correct(fluxes[0], perrs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a043fdf",
   "metadata": {},
   "source": [
    "## Including photon noise as uncertainty on flux\n",
    "\n",
    "Error propagation:\n",
    "\n",
    "m = -2.5 * x + B\n",
    "\n",
    "=> x = log10(F) = flux\n",
    "\n",
    "=> B = constant due to background\n",
    "\n",
    "sigma_m = uncertainty on m, will depend on F and B according to:\n",
    "\n",
    "=> sigma_m = sqrt( [d_m/d_F * sigma_F]^2 + [d_m/d_B * sigma_B]^2 )\n",
    "\n",
    "dm/dF: -2.5 * d/dF[log10(F)] = -2.5/F*ln(10)\n",
    "\n",
    "dm/dB: 1\n",
    "\n",
    "sigma_B: perr = sqrt(pcov) = std of the fit parameter B\n",
    "\n",
    "sigma_F: could define as std of F by collecting many measurements of F. But, doesn't take all sources into account. e.g. photon noise. Could assume sigma_F is completely due to photon noise. Could compute this by getting std of pixels surronding the satellite trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db531a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.stats as aps\n",
    "lstseq = 48506274\n",
    "data = pf.getdata(f'{starlink_data}test_data/diff_images/LSC/diff_{lstseq}LSC.fits.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6db020d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = 1136 \n",
    "x_max = 869 \n",
    "y_min = 925\n",
    "y_max = 1293\n",
    "\n",
    "if x_min < x_max:\n",
    "    x0 = x_min\n",
    "    x1 = x_max\n",
    "else:\n",
    "    x0 = x_max\n",
    "    x1 = x_min\n",
    "if y_min < y_max:\n",
    "    y0 = y_min\n",
    "    y1 = y_max\n",
    "else:\n",
    "    y0 = y_max\n",
    "    y1 = y_min\n",
    "    \n",
    "def fitmagfunc(x, b):\n",
    "    # magnitude = -2.5 * np.log10(flux) + constant (from background noise)\n",
    "    return -2.5 * x + b    \n",
    "\n",
    "def brightness_err(logF, sigma_F, sigma_B):\n",
    "    F = 10**logF\n",
    "    dm_dF = -2.5/(F*np.log(10))\n",
    "    dm_dB = 1\n",
    "    sigma_m = np.sqrt( (dm_dF * sigma_F)**2 + (dm_dB * sigma_B)**2 )\n",
    "    return sigma_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c61c33ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 5.4297 +/- 0.0389\n"
     ]
    }
   ],
   "source": [
    "# Brightness magnitude\n",
    "m = fitmagfunc(fluxes[0], popts[0])\n",
    "\n",
    "# Uncertainty due to photon noise = sigma_F\n",
    "mean, median, sigma_F = aps.sigma_clipped_stats(np.fabs(data[y0:y1, x0:x1]))\n",
    "\n",
    "# Uncertainty due to background noise\n",
    "sigma_B = np.sqrt(pcovs[0])\n",
    "\n",
    "# Now propagate error to estimate uncertainty in the brightness magnitude\n",
    "sigma_m = brightness_err(fluxes[0], sigma_F, sigma_B)\n",
    "\n",
    "print(f'm = {round(m,4)} +/- {round(sigma_m,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4db1c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'47772U': {'start': {'jd': 2459876.522254584,\n",
       "   'lst': 21.978274854520222,\n",
       "   'ra': 311.63254697650916,\n",
       "   'dec': -49.43236302592727,\n",
       "   'x': 2643.497293869421,\n",
       "   'y': 2219.0567380831817},\n",
       "  'end': {'jd': 2459876.5224023364,\n",
       "   'lst': 21.981820919742177,\n",
       "   'ra': 321.3814348461688,\n",
       "   'dec': -43.92129607847961,\n",
       "   'x': 2327.369803741676,\n",
       "   'y': 1905.003180617398},\n",
       "  'JD': 2459876.522291522},\n",
       " '49450U': {'start': {'jd': 2459876.522254584,\n",
       "   'lst': 21.978274854520222,\n",
       "   'ra': 303.995480721863,\n",
       "   'dec': -32.56216180525492,\n",
       "   'x': 3069.235754103156,\n",
       "   'y': 1427.4979091994649},\n",
       "  'end': {'jd': 2459876.5224023364,\n",
       "   'lst': 21.981820919742177,\n",
       "   'ra': 311.9831545763556,\n",
       "   'dec': -26.650709545357753,\n",
       "   'x': 2754.688453914375,\n",
       "   'y': 1089.8309555697506},\n",
       "  'JD': 2459876.522291522}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.read_pickle(f'{starlink_data}full_data/passages_20221023LSC.p')\n",
    "p['48506345']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329097c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tles():\n",
    "    \n",
    "    # Load TLEs for all satellite passages\n",
    "    satfiles = f\"{starlink_data}/test_data/3leComplete.txt\"\n",
    "    with open(satfiles) as f:\n",
    "        all_tles = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "    # Split TLE list into individual lists for each TLE\n",
    "    all_tles = [i.strip() for i in all_tles]\n",
    "    tles = [all_tles[x:x+3] for x in range(0, len(all_tles), 3)]\n",
    "\n",
    "    # Reduce TLEs to Starlink only\n",
    "    starlink_tles = []\n",
    "    for tle in tles:\n",
    "        if \"STARLINK\" in tle[0]:\n",
    "            starlink_tles.append(tle)\n",
    "            \n",
    "    for tle in starlink_tles:\n",
    "        tle[0] = tle[0][2:]\n",
    "        \n",
    "    return starlink_tles\n",
    "\n",
    "tles = get_tles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdce0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def starlink_df(tles, save=False):\n",
    "    \n",
    "    names = []\n",
    "    satnums = []\n",
    "    for tle in tles:\n",
    "        names.append(tle[0])\n",
    "        satnums.append(tle[1][2:8])\n",
    "        \n",
    "    df = pd.DataFrame({'name': names, 'num': satnums})\n",
    "    \n",
    "    if save:\n",
    "        df.to_pickle('starlink_names.p')\n",
    "    return df\n",
    "\n",
    "df = starlink_df(tles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45509f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARLINK-24\n"
     ]
    }
   ],
   "source": [
    "sat = '44238U'\n",
    "name = df.loc[df['num'] == sat, 'name'].values[0]\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c71773a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STARLINK-24</td>\n",
       "      <td>44238U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STARLINK-71</td>\n",
       "      <td>44252U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STARLINK-1007</td>\n",
       "      <td>44713U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STARLINK-1008</td>\n",
       "      <td>44714U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STARLINK-1009</td>\n",
       "      <td>44715U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>STARLINK-5124</td>\n",
       "      <td>54011U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>STARLINK-5126</td>\n",
       "      <td>54012U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>STARLINK-5098</td>\n",
       "      <td>54013U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>STARLINK-5116</td>\n",
       "      <td>54014U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>STARLINK-5055</td>\n",
       "      <td>54015U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3179 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name     num\n",
       "0       STARLINK-24  44238U\n",
       "1       STARLINK-71  44252U\n",
       "2     STARLINK-1007  44713U\n",
       "3     STARLINK-1008  44714U\n",
       "4     STARLINK-1009  44715U\n",
       "...             ...     ...\n",
       "3174  STARLINK-5124  54011U\n",
       "3175  STARLINK-5126  54012U\n",
       "3176  STARLINK-5098  54013U\n",
       "3177  STARLINK-5116  54014U\n",
       "3178  STARLINK-5055  54015U\n",
       "\n",
       "[3179 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc85009",
   "metadata": {},
   "source": [
    "### Could include uncertainties for all the stellar fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "97ccdd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['astrometry', 'header', 'lightcurves', 'stars', 'station']>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc = h5py.File(f'{starlink_data}test_data/fast_20221023LSC.hdf5')\n",
    "lc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a61fb358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lstseq', 'sky', 'esky', 'peak', 'x', 'y', 'pflag', 'aflag', 'tmpmag0', 'tmpemag0', 'cflag', 'flux0', 'flux1', 'eflux0', 'eflux1'])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc['lightcurves']['1188881'].dtype.fields.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "745d0d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([219.93915, 221.60266, 219.29958, 223.87366, 222.74988, 225.32402,\n",
       "       221.58476, 212.9958 , 226.11504, 220.81712, 223.28064, 221.30785,\n",
       "       225.69043, 224.79608, 225.7578 , 227.0835 , 227.69464, 221.47737,\n",
       "       229.92023, 226.71748, 224.8624 , 227.03719, 227.72093, 226.2408 ,\n",
       "       221.90656, 230.79414, 227.77919, 223.47311, 223.8087 , 231.99716,\n",
       "       228.83308, 233.85834, 225.295  , 221.20934, 219.96484, 226.56836],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc['lightcurves']['1188881']['eflux1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d0ded646",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b8d02d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bringreduce.configuration as cfg\n",
    "cfg.initialize('20221023LSC')\n",
    "starcat = pf.getdata(cfg.starcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e584a0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ASCC', 'Blend', 'Bmag', 'Dist10', 'Dist6', 'Dist8', 'Duplicate',\n",
       "       'GDE', 'GRA', 'Gmag', 'HD', 'HIP', 'Inclusion', 'Par', 'SKYIDX',\n",
       "       'SpType', 'TYC1', 'TYC2', 'VSXid', 'Var', 'Vmag', '_DEJ2000',\n",
       "       '_RAJ2000', 'ePar'], dtype='<U9')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(starcat.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7e6b97d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20,  6, 16, ...,  0,  0,  4], dtype=uint8)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starcat['Var']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88541f",
   "metadata": {},
   "source": [
    "## Sources of uncertainty from difference image (repeated 10 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c737f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'{starlink_data}error_tests/*.fits.gz')\n",
    "files = sorted(files, key=lambda x: int(re.search(r'\\d+', x).group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "301dde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = pf.getdata(files[i])\n",
    "    ax.imshow(img, vmin=-15, vmax=100, cmap='terrain')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('error_tests_5.png', facecolor='w', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef154435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(pixels):\n",
    "    mean = np.mean(pixels)\n",
    "    sdev = np.std(pixels)\n",
    "    median = np.median(pixels)\n",
    "    return mean, sdev, median\n",
    "\n",
    "def evaluate_noise(img):\n",
    "    pixels = img.flatten()\n",
    "    noise_sdev = np.std(pixels)\n",
    "    return noise_sdev\n",
    "\n",
    "def noise_sources(images, threshold):\n",
    "    # Need to define the expected noise characteristics i.e. a threshold\n",
    "    for img in images:\n",
    "        noise_sdev = evaluate_noise(img)\n",
    "        if noise_sdev > threshold:\n",
    "            print(\"Readout noise\")\n",
    "        else:\n",
    "            print(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b3e95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 2\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 3\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 4\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 5\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 6\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 7\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 8\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 9\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n",
      "Image 10\n",
      "Mean: -0.011657438282518468\n",
      "Standard Deviation: 33.479822110727675\n",
      "Median: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, f in enumerate(files, start=1):\n",
    "    print(f'Image {i}')\n",
    "    img = pf.getdata(f)\n",
    "    pixels = img.flatten()\n",
    "    mean, sdev, median = calculate_statistics(pixels)\n",
    "    print(\"Mean:\", mean)\n",
    "    print(\"Standard Deviation:\", sdev)\n",
    "    print(\"Median:\", median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aaca59",
   "metadata": {},
   "source": [
    "Since all 10 delta images have the exact same mean, sdev, and median for the pixel values, this suggests that the noise characteristics in those images are consistent. \n",
    "\n",
    "i.e. this implies that the noise sources contributing to the delta images, such as photon noise, readout noise, dark current noise, and systematic noise, are relatively stable and have similar magnitudes across the dataset.\n",
    "\n",
    "Photon Noise: If the standard deviation of the pixel values is consistent across the delta images, it suggests that the photon noise contribution to the images is stable. Photon noise is generally proportional to the square root of the signal level, and a consistent standard deviation indicates a consistent signal level across the images.\n",
    "\n",
    "Readout Noise: The identical mean, standard deviation, and median values across the delta images suggest that the readout noise component is relatively constant. Readout noise arises from the electronics in the image acquisition process and is typically independent of the signal level. Therefore, the consistent noise characteristics indicate a stable readout noise contribution.\n",
    "\n",
    "Dark Current and Systematic Noise: If the noise characteristics are identical across the delta images, it suggests that the contributions from dark current noise and systematic noise are also consistent. Dark current noise is caused by thermal effects in the camera sensor and can vary with exposure time and temperature. However, if the noise characteristics are consistent, it implies a stable dark current contribution. Systematic noise, arising from calibration errors or instrumental effects, would also be consistent across the images.\n",
    "\n",
    "In summary, the consistent noise characteristics in the delta images indicate stability in the noise sources and suggest that the observed variations are primarily due to the satellite trails rather than noise fluctuations. This provides a more reliable foundation for analyzing and quantifying the impact of satellite trails in observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934af5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
